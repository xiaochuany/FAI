{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "494689e0-9b6b-46c1-8175-7dcfef96a8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uncomment for the first run\n",
    "# !pip install kaggle\n",
    "# !kaggle competitions download -c spaceship-titanic\n",
    "# !unzip space*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b151da-95ec-4be6-9eb6-9ca10b4ce318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preprocess\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# eval\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18236084-7c7e-485f-a933-b9bd01069400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0ac1bc8-993e-4b2e-b9eb-e35b1b037e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall    Spa  VRDeck             Name  \\\n",
       "0          0.0        0.0           0.0    0.0     0.0  Maham Ofracculy   \n",
       "1        109.0        9.0          25.0  549.0    44.0     Juanna Vines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "716e7342-4725-4820-9f86-ebe43d0eabff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67781436-1ad5-46fe-a884-55dd514524e8",
   "metadata": {},
   "source": [
    "# Boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c875cd-2429-4590-9d5f-698dfa5140fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Handling missing values by imputing with the most common value (mode)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        # For object (categorical) columns, impute with the most common value (mode)\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    else:\n",
    "        # For numeric columns, impute with the mean (you can choose other methods like median as well)\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# Step 2: Split the data into features (X) and target (y) which needs to be integer for gradient boosting model\n",
    "X = df.drop('Transported', axis=1)\n",
    "y = df['Transported']\n",
    "y = y.astype(int)\n",
    "\n",
    "# Step 3: Encoding categorical variables (if any)\n",
    "# If there are categorical variables in your data, you need to encode them as numerical values\n",
    "# For simplicity, we'll use LabelEncoder for this example\n",
    "# You may consider using OneHotEncoder for nominal categorical variables or other encoders for specific cases\n",
    "label_encoder = LabelEncoder()\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    X[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "# Step 4: Split the data into training and dev sets\n",
    "# We will use 80% of the data for training and 20% for dev\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "596f2231-382e-4d1b-88e8-0de5d4e19c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7929844738355377\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78       861\n",
      "           1       0.77      0.83      0.80       878\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.79      0.79      0.79      1739\n",
      "weighted avg       0.79      0.79      0.79      1739\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[647 214]\n",
      " [146 732]]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Instantiate the gradient boosting classifier\n",
    "# For simplicity, we'll use default hyperparameters\n",
    "gbc = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# Step 6: Train the Random Forest classifier\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Make predictions on the dev data\n",
    "y_pred = gbc.predict(X_dev)\n",
    "\n",
    "# Step 8: Evaluate the performance of the Random Forest model\n",
    "accuracy = accuracy_score(y_dev, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# You can also print other metrics like classification report and confusion matrix\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_dev, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_dev, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dda9bb4-751b-4d0f-a0be-a3988bf06221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the test data\n",
    "X_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Step 1: handle missing values the same way as we did for the training+dev set\n",
    "for col in X_test.columns:\n",
    "    if X_test[col].dtype == 'object':\n",
    "        X_test[col].fillna(X_test[col].mode()[0], inplace=True)\n",
    "    else:\n",
    "        X_test[col].fillna(X_test[col].mean(), inplace=True)\n",
    "\n",
    "# Step 2: Encode categorical variables, same encoder as for training dev splits\n",
    "for col in X_test.select_dtypes(include='object').columns:\n",
    "    X_test[col] = label_encoder.fit_transform(X_test[col])\n",
    "\n",
    "# Step 3: Make predictions on the unseen data using the trained model\n",
    "y_pred = gbc.predict(X_test)\n",
    "y_pred = y_pred.astype(bool)\n",
    "\n",
    "# log the prediction in the submission file\n",
    "df_submission = pd.read_csv('sample_submission.csv')\n",
    "df_submission['Transported'] = y_pred\n",
    "df_submission.to_csv('submission_gbbase.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5f25ff9-10a5-47e0-9b31-25e84e068626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c spaceship-titanic -f submission_gbbase.csv -m \"gradient boosting baseline\"\n",
    "# !kaggle competitions submissions -c spaceship-titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56f900-aea1-46a4-b430-31943f5e4429",
   "metadata": {},
   "source": [
    "## hpyerparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461b7f90-0f28-42a8-a157-9e8dafe8d770",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters from Randomized Search: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 3, 'learning_rate': 0.2}\n",
      "Best Model Accuracy from Randomized Search: 0.7981598619896493\n"
     ]
    }
   ],
   "source": [
    "# only done random search. can do grid search as well by commenting out the relevant lines\n",
    "\n",
    "\n",
    "# Step 3: Define the hyperparameter grid for Grid Search or Randomized Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],             # Number of boosting stages to be run\n",
    "    'learning_rate': [0.01, 0.1, 0.2],           # Step size shrinkage used in updating weights\n",
    "    'max_depth': [3, 5, 7],                      # Maximum depth of the individual trees\n",
    "    'min_samples_split': [2, 5, 10],             # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],               # Minimum samples required to be at a leaf node\n",
    "    # You can add more hyperparameters to the grid based on your requirement\n",
    "}\n",
    "\n",
    "\n",
    "# # Step 4: Perform Grid Search\n",
    "# grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Step 5: Get the best hyperparameters and corresponding model\n",
    "# best_params_grid = grid_search.best_params_\n",
    "# best_rf_model_grid = grid_search.best_estimator_\n",
    "\n",
    "# Step 6: Perform Randomized Search\n",
    "randomized_search = RandomizedSearchCV(gbc, param_distributions=param_grid, n_iter=10, cv=5, n_jobs=-1)\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Get the best hyperparameters and corresponding model from Randomized Search\n",
    "best_params_random = randomized_search.best_params_\n",
    "best_gbc_random = randomized_search.best_estimator_\n",
    "\n",
    "# Step 8: Evaluate the best models on the test data\n",
    "# accuracy_grid = best_rf_model_grid.score(X_dev, y_dev)\n",
    "accuracy_random = best_gbc_random.score(X_dev, y_dev)\n",
    "\n",
    "# print(\"Best Hyperparameters from Grid Search:\", best_params_grid)\n",
    "# print(\"Best Model Accuracy from Grid Search:\", accuracy_grid)\n",
    "\n",
    "print(\"Best Hyperparameters from Randomized Search:\", best_params_random)\n",
    "print(\"Best Model Accuracy from Randomized Search:\", accuracy_random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fb798cb-4029-4c9c-8149-7e53a83448fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inference on the test data (already processed earlier)\n",
    "y_pred = best_gbc_random.predict(X_test)\n",
    "y_pred = y_pred.astype(bool)\n",
    "# log predictions in the submision file\n",
    "df_submission = pd.read_csv('sample_submission.csv')\n",
    "df_submission['Transported'] = y_pred\n",
    "df_submission.to_csv('submission_gbtuned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e935e41b-6623-46b1-9379-b2ba08e22c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c spaceship-titanic -f submission_gbtuned.csv -m \"gradient boosting tuned\"\n",
    "# !kaggle competitions submissions -c spaceship-titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b4c21-bc19-4879-8346-401e71bb52a9",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c215544-b316-4911-bf69-a1bb6b2e0e23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b76ef33-0bd4-4454-88b9-a7f17a1009b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the learned parameters and the estimator using joblib\n",
    "joblib.dump(gbc, 'gbc_tuned.pkl')\n",
    "# Load the model\n",
    "gbc_load = joblib.load('gbc_tuned.pkl')\n",
    "# Use the loaded model for predictions\n",
    "y_pred_reload = gbc_load.predict(X_test)\n",
    "\n",
    "# all(y_pred_reload == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb908db-e9c3-47b7-ade1-ead658fb481d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scipy:Python",
   "language": "python",
   "name": "conda-env-scipy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
